{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2dba1830-4bcf-4d22-9b8c-128a73f3be12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "from scipy import sparse\n",
    "import scipy\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e267d9-6fcc-41a1-bd7f-df1cb3dd8f31",
   "metadata": {},
   "source": [
    "# Prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1640d8c-5426-44b9-8365-b9d1e42a90f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet('train_mfti.parquet', engine='pyarrow')\n",
    "\n",
    "users_cookies = df[df['user_id'].notna()].groupby(['cookie_id'], as_index=False)['user_id'].agg(['unique'])\n",
    "users_cookies_list = users_cookies.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d46ec8-3c97-4972-a514-7901cdad3cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_id_unknown(cookie):\n",
    "    if cookie in users_cookies_list:\n",
    "        return users_cookies.loc[cookie][0][0]\n",
    "    else:\n",
    "        return cookie\n",
    "    \n",
    "arr_new_id = list()\n",
    "for i in df['cookie_id']:\n",
    "    arr_new_id.append(set_id_unknown(i))\n",
    "    \n",
    "df.insert(6, \"new_id\", arr_new_id, True)\n",
    "print(df[df['new_id'].isna()]['new_id'].sum() == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0fedfd3-d369-45a7-a765-6ff8489ab5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('with_new_ids.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5315fe3f-1b70-4754-b992-be27a096ab0a",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6ab5c7-2be5-42b4-8493-81094f43b3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('with_new_ids.csv', engine='c')\n",
    "df.drop(['user_id', 'event_date'], axis=1, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97080ab4-27b2-4858-879c-efc0cb444c06",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca87da6a-f817-4da3-85fb-8ddc6d638c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default\n",
    "def create_massive(original_df, file_name):\n",
    "    uniq_users_id = original_df['new_id'].unique()\n",
    "    uniq_vacancy = original_df['vacancy_id_'].unique()\n",
    "    size = len(uniq_vacancy)\n",
    "    \n",
    "    interactions = original_df.query('event_type != \"preview_click_vacancy\" and event_type != \"show_vacancy\"') \\\n",
    "    .groupby(['new_id', 'vacancy_id_', 'event_type'], as_index=False) \\\n",
    "    .agg({'event_timestamp': 'count'})\n",
    "\n",
    "    massive = np.zeros((len(uniq_users_id), size), dtype='int8')  \n",
    "    for k1, i in enumerate(tqdm.tqdm(uniq_users_id)):\n",
    "        user_vacancies = set(interactions[interactions['new_id'] == i]['vacancy_id_'])\n",
    "        for k2, w in enumerate(uniq_vacancy):\n",
    "            if w in user_vacancies: massive[k1][k2] = 1\n",
    "\n",
    "    massive = pd.DataFrame(data = massive, index=uniq_users_id, columns=uniq_vacancy)\n",
    "    return massive\n",
    "\n",
    "# def create_massive(original_df, file_name):\n",
    "#     uniq_users_id = original_df['new_id'].unique()\n",
    "#     uniq_vacancy = original_df['vacancy_id_'].unique()\n",
    "#     size = len(uniq_vacancy)\n",
    "    \n",
    "#     interactions = original_df.groupby(['new_id', 'vacancy_id_', 'event_type'], as_index=False) \\\n",
    "#     .agg({'event_timestamp': 'count'})\n",
    "\n",
    "#     massive = np.zeros((len(uniq_users_id), size), dtype='int8')  \n",
    "#     for k1, i in enumerate(tqdm.tqdm(uniq_users_id)):\n",
    "#         user_vacancies = set(interactions[interactions['new_id'] == i]['vacancy_id_'])\n",
    "#         for k2, w in enumerate(uniq_vacancy):\n",
    "#             if w in user_vacancies: massive[k1][k2] = 1\n",
    "\n",
    "#     massive = pd.DataFrame(data = massive, index=uniq_users_id, columns=uniq_vacancy)\n",
    "#     return massive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b274dd2-8433-44a0-8ac5-6cb188b9bd96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get vectorized users\n",
    "vectors = create_massive(df, 'vectors_wout_show_preview')\n",
    "\n",
    "sparse_vectors = sparse.csr_matrix(vectors)\n",
    "scipy.sparse.save_npz('sparse_massive.npz', sparse_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6682188f-dc21-46fc-bad9-e881840ead75",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity = cosine_similarity(sparse_vectors, dense_output=False)\n",
    "changed_similarity = similarity.astype(dtype='float16', copy=True)\n",
    "scipy.sparse.save_npz('changed_similarity_results.npz', changed_similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90306b1-eda6-435b-b931-55d62aea5976",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8859aa90-4c2c-4fd7-bab4-2b7b6ebf9c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "changed_similarity = scipy.sparse.load_npz('changed_similarity_results.npz')\n",
    "A = pd.DataFrame.sparse.from_spmatrix(changed_similarity)\n",
    "display(A) # матрица юзер х юзер, на пересечении похожесть"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1095ff96-7aa7-45d0-a3ac-a80576451d28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef966f6c-924e-4f92-8425-9adc962c0b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# f5 = 0.0189\n",
    "\n",
    "# куки и соответствующие id юзеров\n",
    "users_cookies = df.groupby(['cookie_id'], as_index=False)['new_id'].agg(['unique'])\n",
    "\n",
    "# тут уже все действия юзеров\n",
    "interactions = df.groupby(['new_id', 'vacancy_id_', 'event_type'], as_index=False) \\\n",
    ".agg({'event_timestamp': 'count'}) \\\n",
    ".sort_values(['event_timestamp'], ascending=False)\n",
    "\n",
    "# default vacancies to give\n",
    "top_vacancies = df.pivot_table(index='vacancy_id_', columns='event_type', values='event_timestamp', aggfunc='count', fill_value=0)\n",
    "top_vacancies['ctr'] = top_vacancies.apply(lambda x: (x['preview_click_vacancy'] + x['click_response'] + x['click_contacts'] + x['preview_click_response']+ x['click_favorite'] + x['preview_click_favorite'] + x['preview_click_contacts'] + x['click_phone'] + x['preview_click_phone'])/x['show_vacancy'] if x['show_vacancy'] != 0 else 0, axis=1)\n",
    "top_vacancies = list(top_vacancies.sort_values(['ctr'], ascending=False).index[:5])\n",
    "\n",
    "# Получить new_id/user_id по куки\n",
    "def get_new_id_by_cookie(cookie):\n",
    "    return users_cookies.loc[cookie][0][0]\n",
    "\n",
    "# Лист всех уникальных юзеров по-порядку, в котором составлялась матрица\n",
    "user_unique_columns = df['new_id'].unique()\n",
    "# Получить индекс юзера в списке\n",
    "def get_user_index(user_id):\n",
    "    return np.where(user_unique_columns == user_id)[0][0]\n",
    "\n",
    "# Получение вакансий для рекомендации\n",
    "def get_similar_users_ordered(user_index):\n",
    "    similar_users_index_list = list()\n",
    "    for i, val in enumerate(A[user_index]):\n",
    "        if (val > 0) and (i != user_index):\n",
    "            similar_users_index_list.append((i, val))\n",
    "    similar_users_index_list = sorted(similar_users_index_list, key = lambda x: x[1], reverse=True)\n",
    "    return similar_users_index_list\n",
    "\n",
    "# Ранжирование товаров юзера\n",
    "def get_vacancies_ordered_by_user(new_id):\n",
    "    user_interaction = interactions[interactions['new_id'] == new_id]\n",
    "    unique_user_events = user_interaction['event_type'].unique()\n",
    "\n",
    "    vacancy_table = user_interaction.pivot_table(index='vacancy_id_', columns='event_type', values='event_timestamp', fill_value=0).reset_index()\n",
    "    vacancy_table['ctr'] = vacancy_table.apply(lambda x: (sum([x[i] for i in unique_user_events])), axis=1)\n",
    "    vac_dict = list([[v['vacancy_id_'] , v['ctr']] for i, v in vacancy_table.iterrows()])\n",
    "    return sorted(vac_dict, key = lambda x: x[1], reverse=True)\n",
    "\n",
    "# Получение отранжированных вакансий по всем юзерам\n",
    "def get_ordered_vacancies(similar_users_list):\n",
    "    recommend_vac = list()\n",
    "    for i in similar_users_list[:15]: # пока беру первых 15 похожих юзеров\n",
    "        user = user_unique_columns[i[0]]\n",
    "        vacancies = get_vacancies_ordered_by_user(user)\n",
    "        for v in vacancies:\n",
    "            recommend_vac.append(v[0])\n",
    "    recommend_vac = list(dict.fromkeys(recommend_vac))\n",
    "    return recommend_vac\n",
    "\n",
    "\n",
    "# Получить использованные вакансии\n",
    "def get_used_vacancies(new_id):\n",
    "    return interactions[interactions['new_id'] == new_id]['vacancy_id_'].unique()\n",
    "    \n",
    "    \n",
    "# Получение рекомендации\n",
    "def get_user_recommendation(cookie, size=5):\n",
    "    recommend_result = []\n",
    "    user_id = get_new_id_by_cookie(cookie)\n",
    "    index = get_user_index(user_id)\n",
    "    similar_index_list = get_similar_users_ordered(index)\n",
    "    \n",
    "    all_recommended_vac = get_ordered_vacancies(similar_index_list)\n",
    "    users_used_vacs = get_used_vacancies(user_id)\n",
    "    \n",
    "    if len(all_recommended_vac) > 0:\n",
    "        for i in all_recommended_vac:\n",
    "            if i not in users_used_vacs:\n",
    "                recommend_result.append(i)\n",
    "    else:\n",
    "        return top_vacancies\n",
    "    return recommend_result[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4084430d-ae56-424b-9a02-a44a05e69cb4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d414bb-6fb8-4332-a2eb-947caba20f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_parquet('test_public_mfti.parquet', engine='pyarrow')\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d8ae6a-7ed0-49ab-b497-c9e4704e7f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_prediciton(cookies):\n",
    "    lst = []\n",
    "    for cookie in tqdm.tqdm(cookies):\n",
    "        prediction = get_user_recommendation(cookie)\n",
    "        lst.append(prediction)\n",
    "    return lst\n",
    "\n",
    "test_df['predicted'] = make_prediciton(test_df['cookie_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b489c7-d74e-420c-a71f-4c24068f30f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['true_positive'] = test_df.apply(lambda x: len(set(x['vacancy_id_']) & set(x['predicted'])), axis=1)\n",
    "test_df['f5'] = test_df.apply(lambda x: len(set(x['vacancy_id_']) & set(x['predicted'])) / 5, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6cbd57-df25-4801-9214-cbf88a0c4171",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df[test_df['true_positive'] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04daa34d-f1ab-4e8a-94b9-da39177353b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['f5'].mean() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b25dc7e6-c001-4497-9b5c-2744d138c909",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b98c0db-1a0a-4167-97b5-d7d0c64727c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.to_csv('result_0_1.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
